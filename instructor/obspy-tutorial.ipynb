{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22ad02eb",
   "metadata": {},
   "source": [
    "# Working with Jupyter Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8a82a8",
   "metadata": {},
   "source": [
    "A Jupyter Notebook is a web-based application that allows you to create and share documents containing live code, text, visualizations, and other rich media. A cell is the basic unit of interaction in a notebook. A cell can contain code or [markdown](https://jupyter-notebook.readthedocs.io/en/stable/examples/Notebook/Working%20With%20Markdown%20Cells.html).\n",
    "\n",
    "\n",
    "You can select the type of cell from the menu above. \n",
    "\n",
    "![](../images/select_cell_type.png)\n",
    "\n",
    "Then select the '+' from the menu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4089bbe0",
   "metadata": {},
   "source": [
    "If you select **Markdown**, the cell can format text and code. We can use it to add notes, images, and detailed comments in the notebook. A basic cheat sheet as a notebook is [included](Markdown-Cheat-Sheet.ipynb). \n",
    "\n",
    "If you select **Code** then you can write Python code and run it in the cell.\n",
    "\n",
    "Let's look at the example code below. Programs are built from smaller programs called packages. The first thing we do is import the `datetime` package which lets you manipulate dates and time.\n",
    "\n",
    "The following sections are `functions` is a block of code that runs when called. You can pass data or parameters to the funciton. Functions increase code reusability and readability. Functions follow the `DRY` or \"Don't Repeat Yourself\" principal which is guideline to avoid code duplication. Functions are defined with `def` keyword, the name of the function followed by parameters, and terminated with a colon. The following code is indented and `return` sends the result back to the code that called the function.\n",
    "\n",
    "The program flow is:\n",
    "\n",
    "1. Call the `date` function to get today's date.\n",
    "2. Call the `format_date_with_ordinal` with today's date.\n",
    "3. The `format_date_with_ordinal` calls the `ordinal_suffix` function to place the correct suffix for the day.\n",
    "4. The `format_date_with_ordinal` returns the formated date.\n",
    "5. The program prints a message with the formatted date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a21df32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a code cell. Run this python example by selecting the 'play' icon in the menu\n",
    "\n",
    "from datetime import date\n",
    "\n",
    "def ordinal_suffix(day):\n",
    "    if 10 <= day <= 20:\n",
    "        suffix = 'th'\n",
    "    else:\n",
    "        suffix = {1: 'st', 2: 'nd', 3: 'rd'}.get(day % 10, 'th')\n",
    "    return suffix\n",
    "\n",
    "def format_date_with_ordinal(date_obj):\n",
    "    day = date_obj.day\n",
    "    suffix = ordinal_suffix(day)\n",
    "    return f\"{date_obj.strftime('%B')} {day}{suffix}, {date_obj.year}\"\n",
    "\n",
    "today = date.today()\n",
    "formatted_date = format_date_with_ordinal(today)\n",
    "print(\"\\n\\n Hello, today is\", formatted_date)\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ca2c13",
   "metadata": {},
   "source": [
    "# Introduction to Python with obspy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cc5c11",
   "metadata": {},
   "source": [
    "This section demonstrates how to write Python code in a Jupyter Notebook. We'll use a `obspy`, a Python framework (or package) for processing seismic data. It provides parsers for common file formats, clients to access data centers and seismological signal processing routines which allow the manipulation of seismological time series.\n",
    "\n",
    "We'll start by importing modules from the `obspy` package. It's not necessary to import the entire package, just the function from the module, e.g., `obspy.clients.fdsn`. For a first task, we'll view FDSN data centers that offer web services for acquiring data and create a client object that connects to a data center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d21ddf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from obspy.clients.fdsn import Client\n",
    "from obspy.clients.fdsn.header import URL_MAPPINGS\n",
    "import warnings\n",
    "import cartopy\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# lists the data centers and their names\n",
    "for key in sorted(URL_MAPPINGS.keys()):\n",
    "    print(\"{0:<11} {1}\".format(key,  URL_MAPPINGS[key]))  \n",
    "\n",
    "# creates a client that connects to the IRIS data center\n",
    "client = Client(\"IRIS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c253989f",
   "metadata": {},
   "source": [
    "Notebooks offer flexibility when coding. Typically, it is good practice to import packages and modules at the beginning of a program. A notebook lets you import on-the-fly and maintains the previous import. In this case, we're import `UTCDateTime` from obspy because it is based on high precision timestamp that the Python `datetime` class does not offer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c66610",
   "metadata": {},
   "outputs": [],
   "source": [
    "from obspy import UTCDateTime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f5d872",
   "metadata": {},
   "source": [
    "## Getting Event Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c912766a",
   "metadata": {},
   "source": [
    "We can find events using a start date and end date. If we wanted to find earthquakes in 2020 with a magnitude of 7 or greater, we can use obspy's [`get_events` method](https://docs.obspy.org/packages/autogen/obspy.clients.fdsn.client.Client.get_events.html). The method has arguments such as time, coordinates, magnitude, and many others to find earthquakes.\n",
    "\n",
    "> **Client.get_events**(*starttime=None*, *endtime=None*, *minlatitude=None*, *maxlatitude=None*, *minlongitude=None*, *maxlongitude=None*, *latitude=None*, *longitude=None*, *minradius=None*, *maxradius=None*, *mindepth=None*, *maxdepth=None*, *minmagnitude=None*, *maxmagnitude=None*, *magnitudetype=None*, *eventtype=None*, *includeallorigins=None*, *includeallmagnitudes=None*, *includearrivals=None*, *eventid=None*, *limit=None*, *offset=None*, *orderby=None*, *catalog=None*, *contributor=None*, *updatedafter=None*, *filename=None*, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8118ddb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "starttime = UTCDateTime(\"2020-01-01\")\n",
    "endtime = UTCDateTime(\"2025-12-31\")\n",
    "cat = client.get_events(starttime=starttime, endtime=endtime, minmagnitude=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36342fe1",
   "metadata": {},
   "source": [
    "The events are stored in a [`Catalog`](https://docs.obspy.org/packages/autogen/obspy.core.event.Catalog.html) which is a list-like container for `events`. The table lists the methods for the Catalog class.\n",
    "\n",
    "| method | description |\n",
    "|-|-|\n",
    "| append | Appends a single Event object to the current Catalog object. |\n",
    "| clear | Clears event list (convenient method). |\n",
    "| copy | Returns a deepcopy of the Catalog object. |\n",
    "| count | Returns the number of Events in the Catalog object. |\n",
    "| extend | Extends the current Catalog object with a list of Event objects. |\n",
    "| filter | Returns a new Catalog object only containing Events which match the specified filter rules. |\n",
    "| plot | Creates preview map of all events in current Catalog object. |\n",
    "| write | Saves catalog into a file. |\n",
    "\n",
    "\n",
    "We can list the number of events in a catalog and plot the on a globe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fe326c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cat.count())\n",
    "cat.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c4a176",
   "metadata": {},
   "source": [
    "Catalogs handle event metadata in a hierarchy that follows the [QuakeML](https://quake.ethz.ch/quakeml/) format. The diagram shows `Event` metadata has `origins` which includes latitude, longitude, depth, and time.\n",
    "\n",
    "![](../images/Event.png)\n",
    "\n",
    "Let's get an individual event from the catalog. Catalogs behave like Python lists and we can use the lis index to get the time of a single event. The example below, extracts the time for the first event in the catalog "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48caf7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = cat[0].origins[0].time\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2401a930",
   "metadata": {},
   "source": [
    "We get a stream of waveforms with the `get_waveforms` method. The method takes several arguments or parameters that are [documented](https://docs.obspy.org/packages/autogen/obspy.clients.fdsn.client.Client.get_waveforms.html).\n",
    "\n",
    "> **Client.get_waveforms**(*network*, *station*, *location*, *channel*, *starttime*, *endtime*, *quality=None*, *minimumlength=None*, *longestonly=None*, *filename=None*, *attach_response=False*, **kwargs)\n",
    "\n",
    "Using the time from the previous cell, we retrieve data from **IU**, the global network, and use wildcards for the station and location. We specify `LHZ` as the instrument channel and set the time for one minute before the event and fifteen minutes after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab19d70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "st = client.get_waveforms(\"IU\", \"*\", \"*\", \"LHZ\", t - 60 * 5, t + 60 * 120)\n",
    "print(st)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0fc9e0",
   "metadata": {},
   "source": [
    "`get_waveforms` returns a stream which contains a list of `traces`. A trace is gap-less continuous time series and metadata. Let's examine the first trace in the stream and print the metadata using the `stats` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4724e141",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(st))\n",
    "tr = st[0]\n",
    "print(tr.stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b24b187",
   "metadata": {},
   "source": [
    "`stats` lets you access invidual metadata elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349bc828",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tr.stats.network)\n",
    "print(tr.stats.station)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed58511",
   "metadata": {},
   "source": [
    "We can acces the data in a trace with the `data` method. It returns a list of values as a [numpy](https://numpy.org/) array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035aa469",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tr.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f2b79a",
   "metadata": {},
   "source": [
    "The trace can also be plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24959685",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fea4de",
   "metadata": {},
   "source": [
    "## Removing Instrument Response\n",
    "\n",
    "As-is, the trace data doesn't represent ground motion. The data includes instrument response which is a byproduct of how a seismometer converts the analog voltage signal of the instrument of to digital `counts`. To convert the data to actual ground velocity, we have to account for the digitizer and seismometer response to ground motion. The theory and method for removing instrument response is detailed in [Havskov and Alguacil, 2015](https://books.google.com/books?id=5PPuCgAAQBAJ&pg=PA197#v=onepage&q&f=false).\n",
    "\n",
    "Obspy can download the trace data with the instrument response. When we remove instrument response, the data is converted to displacement, velocity, or acceleration data. We'll use the metadata from the previous trace.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038c7b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = \"IU\"\n",
    "station = \"AFI\"\n",
    "location = \"00\"\n",
    "channel = \"LHZ\"\n",
    "starttime = UTCDateTime(\"2025-02-08T23:18:15.069538Z\")\n",
    "endtime = UTCDateTime(\"2025-02-09T01:23:14.069538Z\")\n",
    "\n",
    "st = client.get_waveforms(network, station, location, channel, starttime, endtime, attach_response = True)\n",
    "print(\"\\n\", st)\n",
    "st.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b2d06c",
   "metadata": {},
   "source": [
    "Removing response acts on the data itself and changes it. For each type of output, make a copy of the trace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd46e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copies the trace and removes instrument response\n",
    "st_displacement = st.copy()\n",
    "st_displacement.remove_response(output = 'DISP')\n",
    "\n",
    "# uncomment these to make a copy of the trace\n",
    "#st_velocity = st.copy()\n",
    "#st_acceleration = st.copy()\n",
    "\n",
    "# uncomment these to remove response for these output units\n",
    "# st_velocity.remove_response(output = 'VEL')\n",
    "# st_acceleration.remove_response(output = 'ACC')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b1805b",
   "metadata": {},
   "source": [
    "Let's compare the original trace with the removed response for displacement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb69402",
   "metadata": {},
   "outputs": [],
   "source": [
    "st.plot()\n",
    "st_displacement.plot(); # units in meters\n",
    "\n",
    "# uncomment these plots to visualize the waveforms\n",
    "# st_acceleration.plot(); # units in meters/second^2\n",
    "# st_velocity.plot(); # units in meters/second\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb28473",
   "metadata": {},
   "source": [
    "We can plot the deconvolution process (the conversion of the waveform from the time domain to the frequency domain and the removal of instrument response). The charts on the left are in the frequency domain and the charts on the right are the data in the time domain. \n",
    "\n",
    "The raw data spectrum decomposes the time series into its constituent frequencies, revealing the amplitude and phase of each frequency component. It indicates how strongly each frequency is represented in the signal and serves as a baseline for comparing the effects of instrument response removal. The second frequency chart shows how applying filters can enhance or suppress specific frequency bands to isolate specific seismic phases or reducing noise. The third chart isolates the ground motion signal from the instrument resonse by multiplying the inverted against the raw data to adjust the amplitude and phase of each frequency component in the raw data, which corrects distortions attributable to the instrument. Note that the `water_level` parameter is used to dampen the effect of small values that can introduce noise to the deconvolution process.\n",
    "\n",
    "The parameters for the `remove_response` method are:\n",
    "\n",
    "| parameter | description |\n",
    "| - | - |\n",
    "| inventory  (Inventory or None.) | Station metadata to use in search for adequate response. |\n",
    "| output| Output units |\n",
    "| | \"DISP\" | displacement, output unit is meters |\n",
    "| | \"VEL\" | velocity, output unit is meters/second |\n",
    "| | \"ACC\" | acceleration, output unit is meters/second**2 |\n",
    "| | \"DEF\" | default units, the response is calculated in output units/input units. |\n",
    "| water_level | Water level for deconvolution. |\n",
    "| pre_filt |  Apply a bandpass filter in frequency domain to the data before deconvolution. The list or tuple defines the four corner frequencies (f1, f2, f3, f4) of a cosine taper which is one between f2 and f3 and tapers to zero for f1 < f < f2 and f3 < f < f4. |\n",
    "| zero_mean | If True, the mean of the waveform data is subtracted in time domain prior to deconvolution. |\n",
    "| taper | If True, a cosine taper is applied to the waveform data in time domain prior to deconvolution. |\n",
    "| taper_fraction | Taper fraction of cosine taper to use. |\n",
    "| plot | If True, brings up a plot that illustrates how the data are processed in the frequency domain. |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2af3968",
   "metadata": {},
   "outputs": [],
   "source": [
    "st_velocity = st.copy()\n",
    "st_velocity.remove_response(output = 'DISP', plot = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bca0fe8",
   "metadata": {},
   "source": [
    "## Manipulating Seismic Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feea1dc1",
   "metadata": {},
   "source": [
    "##### The stream and trace objects in Obspy both have public methods that can modify the data. Documentation:\n",
    "\n",
    "- [traces](https://docs.obspy.org/packages/autogen/obspy.core.trace.Trace.html#obspy.core.trace.Trace)\n",
    "- [streams](https://docs.obspy.org/packages/autogen/obspy.core.stream.Stream.html). \n",
    "           \n",
    "There are shared methods between streams and traces, and methods specific to each. Let's look at three shared operations: filtering, trimming, and changing sampling rate.\n",
    "\n",
    "### Filtering\n",
    "\n",
    "Filtering extracts a specific frequency range in a trace or stream. There are many different filter methods available which are described in the [documentation](https://docs.obspy.org/packages/autogen/obspy.core.stream.Stream.filter.html#obspy.core.stream.Stream.filter).\n",
    "\n",
    "1. bandpass\n",
    "2. bandstop\n",
    "3. lowpass\n",
    "4. highpass\n",
    "5. lowpass_cheby_2\n",
    "6. lowpass_fir (experimental)\n",
    "7. remez_fir (experimental)\n",
    "\n",
    "Like `remove_response`, filter operations change the original data and you should copy the stream or trace to retain the unfiltered data for comparison. We can use a bandpass filter to extract the range of frequencies of interest. Let's extract microseismic activity or the hum at [0.003 Hz and 0.015 Hz](https://progearthplanetsci.springeropen.com/articles/10.1186/s40645-023-00587-7)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d084be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy raw data\n",
    "tr_filt = tr.copy()\n",
    "\n",
    "# apply filter\n",
    "tr_filt.filter(\"bandpass\", freqmin=0.003, freqmax=0.015)\n",
    "\n",
    "# plot the trace\n",
    "tr.plot()\n",
    "tr_filt.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cea7c6",
   "metadata": {},
   "source": [
    "### Trimming\n",
    "\n",
    "If we want to focus on just the event we can reduce the amount of data by trimming the stream. The [\"trim\"](https://docs.obspy.org/packages/autogen/obspy.core.stream.Stream.trim.html#obspy.core.stream.Stream.trim) method can set start and end times for and event. Let's trim the data to 30 minutes before the event and 30 minutes after. To do this, we need the start and end times of the stream in UTCDateTime. Previously, we used the stats method to get the metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792e8dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(st[0].stats.starttime)\n",
    "print(st[0].stats.endtime)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac3b95a",
   "metadata": {},
   "source": [
    "Set the new start and end times to 30 minutes before and after. Copy the stream before trimming to keep the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc91b385",
   "metadata": {},
   "outputs": [],
   "source": [
    "starttime = st[0].stats.starttime + 60 * 30\n",
    "endtime = st[0].stats.endtime - 60 * 30\n",
    "\n",
    "tr_trim = tr.copy()\n",
    "\n",
    "tr_trim.trim(starttime=starttime, endtime=endtime)\n",
    "\n",
    "tr.plot()\n",
    "tr_trim.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4079c06",
   "metadata": {},
   "source": [
    "### Sampling Rates\n",
    "\n",
    "Seismic data is resampled for several reasons. If the sampling frequency is high, you might want to reduce or decimate the data. Alternatively, you can increase the sampling rate by interpolating values or resampling the data using the Fourier Method. Increasing the sampling frequency can avoid distortions in the data when the sampling frequency is below the [Nyquist frequency](https://www.geeksforgeeks.org/nyquist-sampling-rate-and-nyquist-interval/). There three methods available in obspy:\n",
    "\n",
    "- [decimate](https://docs.obspy.org/packages/autogen/obspy.core.stream.Stream.decimate.html#obspy.core.stream.Stream.decimate): downsamples by an integer factor\n",
    "- [interpolate](https://docs.obspy.org/packages/autogen/obspy.core.trace.Trace.interpolate.html#obspy.core.trace.Trace.interpolate): increase sampling rate by interpolation\n",
    "- [resample](https://docs.obspy.org/packages/autogen/obspy.core.stream.Stream.resample.html#obspy.core.stream.Stream.resample): resamples data using a Fourier method\n",
    "\n",
    "Let's increase the trimmed trace sampling rate by interpolation. We can find the original sampling rate in the trace metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330779ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nOriginal sampling rate: \",tr_trim.stats.sampling_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb7abbf",
   "metadata": {},
   "source": [
    "As with previous operations, make a copy of the data then apply resampling. Interpolation has many options, consult the documention for the appropriate method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd95b310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the trace\n",
    "tr_resample = tr_trim.copy()\n",
    "\n",
    "# resample by interpolation\n",
    "tr_resample.interpolate(sampling_rate=2, method=\"lanczos\", a=20)\n",
    "\n",
    "# plot the orignal trace and the resampled trace\n",
    "tr_trim.plot()\n",
    "print(\"\\nOriginal sampling rate: \",tr)\n",
    "tr_resample.plot();\n",
    "print(\"\\nNew sampling rate: \", tr_resample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf093841",
   "metadata": {},
   "source": [
    "## Federated Routing Client (Optional)\n",
    "\n",
    "If you want to query more than one data center, the federated routing client supports getting station and waveform data from multiple data centers. There are two federated routing web services, [IRISWS](https://service.iris.edu/irisws/fedcatalog/1/) and [EIDAWS](https://www.orfeus-eu.org/data/eida/webservices/routing/) that returns selected time series channels from across multiple FDSN or EIDA data centers. The interface is primarily designed for discovery of data channels, the subsequent requesting of time series using web service interfaces, and it is capable of removing overlap from the channel list when the same channels are available from multiple data centers, avoiding the request and processing of duplicate data.\n",
    "\n",
    "In this section we'll use the federated routing client to find data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da0b0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from obspy.clients.fdsn import RoutingClient\n",
    "client = RoutingClient(\"iris-federator\")\n",
    "print(type(client))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d010187",
   "metadata": {},
   "source": [
    "The federated routing client can search and retrieve streams. The example below demonstrates how to retrieve streams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c7d203",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = client.get_waveforms(\n",
    "    channel=\"LHZ\", starttime=UTCDateTime(2025, 3, 17),\n",
    "    endtime=UTCDateTime(2025, 3, 18), latitude=-2.872, longitude=130.161,\n",
    "    maxradius=2, extended=True)  \n",
    "print(stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82211759",
   "metadata": {},
   "source": [
    "We can find stations by coordinates and channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573d1e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inv = client.get_stations(\n",
    "    starttime=UTCDateTime(2025, 3, 17),\n",
    "    endtime=UTCDateTime(2025, 3, 18), latitude=-2.872,\n",
    "    level=\"channel\", longitude=130.161, maxradius=2)  \n",
    "print(inv)\n",
    "inv.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05fe9d2",
   "metadata": {},
   "source": [
    "We can find stations by network and station."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ee643f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inventory = client.get_stations(network=\"GE\", station=\"B*\",\n",
    "                                starttime=UTCDateTime(\"2025-03-17\"),\n",
    "                                endtime=UTCDateTime(\"2025-03-18\"),\n",
    "                                level=\"response\")\n",
    "print(inventory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb60b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inventory.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7779060",
   "metadata": {},
   "source": [
    "However, federated routing does not support finding and retrieving events. We have to use the client interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6c2885",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(\"IRIS\")\n",
    "cat = client.get_events(starttime=UTCDateTime(\"2025-03-17\"),\n",
    "                        endtime=UTCDateTime(\"2025-03-18\"), \n",
    "                        minmagnitude=4, latitude=-2.872,\n",
    "                        longitude=130.161, maxradius=1)\n",
    "print(cat)\n",
    "cat.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a34e7ef",
   "metadata": {},
   "source": [
    "We don't know which station has stream data, but `get_waveforms` accepts wildcards for station and location. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216664cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = UTCDateTime(\"2025-03-17T17:32:17.163000Z\")\n",
    "st = client.get_waveforms(\"GE\", \"*\", \"*\", \"LHZ\", t - 60 * 60, t + 60 * 60)\n",
    "st.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
